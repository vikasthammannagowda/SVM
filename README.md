# SVM

**History and Development of Support Vector Machines (SVM)**

**1960s–1980s:**
Vladimir Vapnik and Alexey Chervonenkis develop statistical learning theory, laying the theoretical foundation (generalization, VC dimension).

**Early 1990s:**
The idea of maximum-margin classifiers emerges, framing classification as an optimization problem.

**1992:**
Bernhard Boser, Isabelle Guyon, and Vladimir Vapnik introduce the kernel trick, enabling non-linear decision boundaries.

**1995:**
Corinna Cortes and Vladimir Vapnik publish Support-Vector Networks, defining the modern SVM with soft margins.

**Late 1990s–2000s:**
SVMs become a dominant machine learning method for text classification, vision, and bioinformatics.

**2010s–present:**
SVMs remain widely used, especially for small-to-medium datasets and high-dimensional problems, alongside deep learning.
